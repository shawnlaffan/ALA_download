---
title: "R Notebook"
output: html_notebook
---

Example set of steps to download data from the ALA and then filter them based on QA/QC fields.

Adapted from code used for:
Cassis, G., Laffan, S.W. and Ebach, M.C. (2017) Biodiversity and bioregionalisation perspectives on the historical biogeography of Australia. In Ebach, M.C (ed) Handbook of Australasian Biogeography, ch 1, pp 1-16.
http://www.crcnetbase.com/doi/abs/10.1201/9781315373096-2

That code was in turn adapted from code written by Hugh Burley, who adapted code from Nick dos Remedios at the ALA.


```{r}
library (ALA4R)
library (stringr)
library (rgdal) 
#  needs additional system level libs for this to work
# library (CoordinateCleaner)
```

Configuration section

```{r}
#  make sure we use a local cache on the EcoCloud
if (Sys.getenv("USER") == "jovyan") {
  dir.create("~/ala_cache", showWarnings=FALSE)
  ala_config(cache_directory="~/ala_cache")
}
ala_config (caching="on")
# ala_config (caching="off")
ala_config(warn_on_empty=TRUE)

#  search spatialreference.org for coordinate system definitions
in_prj  <- paste0("+init=epsg:4326") # WGS84 in decimal degrees
out_prj <- paste0("+init=epsg:3577") # Albers equal area projection for Australia

failed <- c()

#  Define a bounding box.
#  The template approach is awkward and inefficient
#  Need a better way, perhaps using sprintf
bbox_template <- "POLYGON((e s, e n, w n, w s, e s))"

#  bbox for the globe
bb <- list (e=180, w=-180, n=90, s=-90)
#  rough bounding box for Australia as WKT format, edit as appropriate
bb <- list (e=154, w=112.9, n=-9, s=-43.74)
#  approx NSW for tests
# bb <- list (e=153, w=140, n=-28, s=-37)

bbox = bbox_template
for (key in names(bb)) {
  bbox <- gsub (key, bb[key], bbox)
}


#  these are the colnames we want in the output
subset_colnames <- c(
  "id",     "x",     "y",       "scientificName",
  "family", "genus", "species", "rank", 
  "coordinateUncertaintyInMetres"
)

```

```{r}

#  Edit as needed.  Some can be case sensitive, so check the ALA website to be certain.
taxon_list <- list (
#   "Araneae"     = "order:ARANEAE",
#   "Daviesia"    = c("genus:Daviesia"),
#   "Acacia"      = c("genus:Acacia"),
#   
   #"Amphibians" = c("family:Hylidae", "family:Myobatrachidae", "family:Microhylidae")
  #"Amphibians" = c("family:Hylidae"),
  # "Bats" = c("molossidae")
  # "Eucs" = c("genus:Corymbia", "genus:Eucalyptus", "genus:Angophora")
  "Eucs" = c("genus:Corymbia")
  
)

taxon_list
```

Create the target directories and download the data.
Note that the directories will be in your current working directory.  

```{r}

for (dir in names(taxon_list)) {
  if (!dir.exists(dir)) {
    print (paste("Creating directory", dir))
    dir.create(dir, showWarnings = TRUE)
    #print (dir.exists(dir))
  }

  collated_df = data.frame()
  
  search_term_vec = taxon_list[[dir]]
  for (i in 1:length(search_term_vec)) { 
    search_term = search_term_vec[i]
    
    rank  = NA
    taxon = search_term
    # hell clunky way of finding a colon
    if (grepl (pattern = ":", x = search_term, fixed=TRUE)) {
      parts = str_split(search_term, pattern = ":")
      rank  = parts[[1]][1]
      taxon = parts[[1]][2]
    }
    
    rds_fname = paste0(dir, "/", taxon, "_ALA_records.rds")
    csv_fname = paste0(dir, "/", taxon, ".csv")
    
    #  skip existing files
    if (file.exists (csv_fname)) {
      print (paste (taxon, ": csv file exists, skipping download"))

      if (length(search_term_vec) > 0) {
        
        ala = readRDS(rds_fname)
        if (nrow(ala)) {
          subset = ala[,subset_colnames]
          if (nrow(collated_df) == 0) {
            collated_df = subset
          } else {
            collated_df = rbind (collated_df, subset)
          }
        }
      }
      #  go to next iteration of loop
      next
    }

    print (paste0 ("Downloading data for ", taxon))
    print (paste0 ("Search term is ", search_term))
    
    ala = data.frame()
    # browser()
    ala = occurrences(taxon=search_term, wkt=bbox, download_reason_id=7)
  
    print (dim (ala$data))
  
    if(is.na(ala) || !is.data.frame(ala$data)){
      print (paste("unable to download records for", taxon))
      failed = append(failed, taxon)
      next
    }

    #  filter valid and non-empty data frames
    if (nrow(ala$data) > 0) {
      # Remove records missing Lat/Long information
      print ("Stripping invalid coords")
      ala$data = ala$data[!(is.na(ala$data$longitude) | is.na(ala$data$latitude)),]
      print (paste ("Rows remaining:", nrow(ala$data)))
      # Remove records that checks indicate are "fatal" (suspicious).
      print ("Checking assertions")
      xa <- check_assertions(ala)
      # Columns of x corresponding to a fatal assertion
      x_afcols <- names(ala$data) %in% xa$occurColnames[xa$fatal]                      
      # Rows of x that have a fatal assertion
      if (sum(x_afcols) > 1) { 
        x_afrows <- which(apply(ala$data[, x_afcols], 1, any))
      } else {  
        x_afrows <- ifelse (
          sum(x_afcols) == 1, 
          which(ala$data[, x_afcols]), 
          NA
        )
      }
      # Reduce to the "clean" data (data rows without fatal assertions)
      if (!any (is.na (x_afrows))) {
        ala$data = ala$data[-x_afrows, ] 
      }
      
      #  we only care about the data frame from here
      ala = ala$data
      
      # Restrict this dataset to only those from Australia
      print ("Excluding records outside bounding box")
      ala = ala[ala$longitude >= bb["w"] & ala$longitude <= bb["e"]
                & ala$latitude >= bb["s"] & ala$latitude <= bb["n"], ]
      print (paste ("Rows remaining:", nrow(ala)))
      # Retain only records with reasonable (<10000m) spatial uncertainty
      #  (still includes NA's)
      print ("Subsetting for coord uncertainty constraint")
      ala <- ala[!is.na(ala$coordinateUncertaintyInMetres)
                 & ala$coordinateUncertaintyInMetres <= 10000 
                 # & !ala$coordinateUncertaintyInMetres %in% c(1,2,3,4)
                 , ]
      print (paste ("Rows remaining:", nrow(ala)))
      
      
      #  coordinatecleaner time
      ##
      # rl <- clean_dataset(ala)
      # ala$dataset = ala$species
      # rl <- clean_dataset(x=ala, lon="longitude", lat="latitude")
      
      if (nrow(ala)) {
        #  add some albers coords
        coords_ll = ala[c("longitude", "latitude")]
        #str(coords_ll)
        coordinates(coords_ll) = coords_ll
        proj4string(coords_ll) = CRS(in_prj)
        coords_albers = as.data.frame(spTransform(coords_ll, CRS=CRS(out_prj)))[, 3:4]
        colnames(coords_albers) = c("x","y")
        #head(coords_albers)
        ala$x = coords_albers$x
        ala$y = coords_albers$y
      } else {
        ala$x = numeric()
        ala$y = numeric()
      }
    } else {
      #browser()
      ala = ala$data
      ala$x = numeric()
      ala$y = numeric()
      #print (colnames(ala))
    }


    if (nrow(ala) > 0) {
      subset = ala[,subset_colnames]
      write.csv(subset, file=csv_fname)

      if (nrow(collated_df) == 0) {
        collated_df = subset
      } else {
        collated_df = rbind (collated_df, subset)
      }
    } else {
      write.csv(data.frame(), file=csv_fname)
    }
  
    saveRDS(ala, file=rds_fname)
  }

  collated_fname = paste0(dir, "/collated.csv")
  write.csv (collated_df, collated_fname)
}
    
```
   

You can of course do things like plot the data.

Perhaps try to make something more aesthetically pleasing to the eye.  

```{r}

dir <- names(taxon_list)[1]
dir 

collated_fname <- paste0(dir, "/collated.csv")

df <- read.csv(collated_fname)

plot (df$x, df$y)

```

    
Things to try:

See if you can edit the code above to use config variables,
i.e. instead of hard coding the error tolerance at 10000, 
why not set it in the config section?

You might also wish to plot the data sets before they are filtered to get a sense of where the errors are.  
